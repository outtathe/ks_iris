{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boYs1URZ7mx2"
      },
      "source": [
        "# Импорт данных и библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ukxvCUEIkDpm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rwF9eVinkXFm"
      },
      "outputs": [],
      "source": [
        "# Чтение файла\n",
        "data_path = '../materials/data/Iris.csv'\n",
        "iris_data = pd.read_csv(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-iTGK5rk0OF"
      },
      "outputs": [],
      "source": [
        "iris_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZFieVxS7ueF"
      },
      "source": [
        "# Восстановление и очистка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZarDH6fc5Apm"
      },
      "outputs": [],
      "source": [
        "# Проверка наличия пропущенных данных\n",
        "missing_data = iris_data.isnull().sum()\n",
        "print(missing_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRBxiQTECMDv"
      },
      "source": [
        "В данном случае, все столбцы - (Id, SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm, Species) не содержат пропусков, и данные готовы для дальнейшей обработки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB39ZrAvCSRY"
      },
      "source": [
        "Пример что делать если пропущенные данные всё же есть:\n",
        "Например, можно использовать среднее значение для заполнения пропусков:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JtFFVpi44Q2"
      },
      "outputs": [],
      "source": [
        "iris_data.fillna(iris_data.mean(), inplace=True)\n",
        "\n",
        "# Проверка, что пропущенных данных больше нет\n",
        "missing_data_after = iris_data.isnull().sum()\n",
        "\n",
        "# Вывод информации о данных после очистки\n",
        "iris_data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU1Zz26yAimF"
      },
      "source": [
        "# Проверка распределения данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I-Guj7A9aY1"
      },
      "outputs": [],
      "source": [
        "# Гистограммы распределения числовых параметров\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
        "\n",
        "sns.histplot(iris_data['SepalLengthCm'], kde=True, ax=axes[0, 0], bins=30, color='skyblue')\n",
        "axes[0, 0].set_title('Sepal Length Distribution')\n",
        "\n",
        "sns.histplot(iris_data['SepalWidthCm'], kde=True, ax=axes[0, 1],bins=30, color='salmon')\n",
        "axes[0, 1].set_title('Sepal Width Distribution')\n",
        "\n",
        "sns.histplot(iris_data['PetalLengthCm'], kde=True, ax=axes[1, 0],bins=30, color='lightgreen')\n",
        "axes[1, 0].set_title('Petal Length Distribution')\n",
        "\n",
        "sns.histplot(iris_data['PetalWidthCm'], kde=True, ax=axes[1, 1],bins=30, color='gold')\n",
        "axes[1, 1].set_title('Petal Width Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Ящиковые диаграммы распределения по классам\n",
        "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(16, 4))\n",
        "\n",
        "for i, column in enumerate(['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']):\n",
        "    sns.boxplot(x='Species', y=column, data=iris_data, ax=axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK8FezxkA00V"
      },
      "source": [
        "Очевидно не нормальное распределение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWjgZF_i_VDq"
      },
      "outputs": [],
      "source": [
        "# матрица диаграмм рассеяния\n",
        "plt.figure(figsize=(15,15))\n",
        "sns.pairplot(iris_data, hue='Species', diag_kind='kde')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocJkqeqHCALK"
      },
      "source": [
        "  Взглянув на график, мы можем увидеть, что, похоже, измерения чашелистиков и лепестков позволяют относительно хорошо разделить три класса. Это означает, что модель машинного обучения, вероятно, сможет научиться разделять их."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8ftfkJOA0Aj"
      },
      "source": [
        "# Проведение EDA и визуализация отобранных параметров (влияющих на целевую переменную)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "n7sN_uaL6WOx",
        "outputId": "e7d24e1f-a94e-4076-b374-eda3937dd807"
      },
      "outputs": [],
      "source": [
        "# Визуализация матрицы корреляции с тепловой картой\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.heatmap(iris_data.corr(),annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcZBzyhcBoJU"
      },
      "source": [
        "Все переменные жестко влияют\n",
        "\n",
        "п.с. это ирисы тут всегда так"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx9LJnw5Dwox"
      },
      "source": [
        "# Разделение набора данных на обучающую и тестовую выборку"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "6Q1W9YafD33S"
      },
      "outputs": [],
      "source": [
        "# Разделение датасета на признаки(Х) и целевую переменную(У)\n",
        "X = iris_data.drop('Species', axis=1)\n",
        "Y = iris_data['Species']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "eNYF0Sn8ERLa"
      },
      "outputs": [],
      "source": [
        "# Разделение датасета на обучающую и тестовую выборку (80% - обучение, 20% - тесты)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify = Y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4PQI21LEtdb"
      },
      "outputs": [],
      "source": [
        "# Вывод размеров полученных выборок\n",
        "print(\"Размер обучающей выборки:\", X_train.shape, Y_train.shape)\n",
        "print(\"Размер тестовой выборки:\", X_test.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNQqbkTfGi0I"
      },
      "source": [
        "# Выдвижение гипотезы о возможных применимых алгоритмах машинного обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfdfQ8J7H3QG"
      },
      "source": [
        "Логистическая регрессия:\n",
        "\n",
        " • Гипотеза: Логистическая регрессия хорошо подходит для бинарной и многоклассовой классификации. Учитывая, что у нас три класса (iris setosa, iris versicolor, iris virginica), логистическая регрессия может быть эффективным методом, особенно если классы хорошо разделимы.\n",
        "\n",
        " • Описание: Логистическая регрессия используется для моделирования вероятности принадлежности к классу. Она основывается на логистической функции, которая преобразует комбинацию признаков в вероятность."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rski_mcrH78l"
      },
      "source": [
        "Дерево решений:\n",
        "\n",
        "• Гипотеза: Деревья решений могут хорошо справляться с нелинейными зависимостями между признаками и целевой переменной. В данной задаче, где параметры могут варьироваться в разных направлениях, деревья решений могут быть гибким и мощным инструментом.\n",
        "\n",
        "• Описание: Дерево решений строит структуру дерева, где каждый узел представляет собой тест на одном из признаков, а каждый лист - прогнозный класс."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OxNO_eOICWk"
      },
      "source": [
        "K-ближайших соседей (KNN):\n",
        "\n",
        "• Гипотеза: KNN может быть эффективным в задачах, где объекты одного класса склонны сгруппироваться в пространстве. В данной задаче, если схожие ирисы образуют группы, KNN может хорошо справляться с классификацией.\n",
        "\n",
        "• Описание: KNN классифицирует объекты на основе их близости к соседним объектам. Когда новый объект появляется, он присваивается класс, который наиболее часто встречается среди k ближайших соседей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x3-6WDVIZx7"
      },
      "source": [
        "# Обучение выбранных моделей (библиотека sklearn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5qBJPQ8Ig1z"
      },
      "source": [
        "## Обучение модели с помощью агоритма логистической регрессии"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6t6A9yIjJP6e"
      },
      "outputs": [],
      "source": [
        "# Создание и обучение модели логистической регрессии\n",
        "logistic_regression_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "logistic_regression_model.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "tdoRxQKDJVp4"
      },
      "outputs": [],
      "source": [
        "# Предсказание на тестовой выборке\n",
        "y_pred_lr = logistic_regression_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "bBO3q08bJbf3"
      },
      "outputs": [],
      "source": [
        "# Оценка производительности модели\n",
        "accuracy_lr = accuracy_score(Y_test, y_pred_lr)\n",
        "conf_matrix_lr = confusion_matrix(Y_test, y_pred_lr)\n",
        "classification_report_lr = classification_report(Y_test, y_pred_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f20XdIkFJ5jT"
      },
      "outputs": [],
      "source": [
        "# Вывод результатов\n",
        "print(\"Accuracy логистической регрессии:\", accuracy_lr)\n",
        "print(\"\\nConfusion Matrix логистической регрессии:\\n\", conf_matrix_lr)\n",
        "print(\"\\nClassification Report логистической регрессии:\\n\", classification_report_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rVxPpNiPnXx"
      },
      "source": [
        "Анализ Confusion matrix для метода логистической регресии:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKWudGmEMCvM"
      },
      "source": [
        "\n",
        "• Все элементы на главной диагонали (10, 10, 10) - это True Positives, что означает, что все объекты каждого класса были верно классифицированы.\n",
        "\n",
        "• Нет False Positives (0 вне главной диагонали) и False Negatives (0 вне главной диагонали), что подтверждает отсутствие ошибок классификации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa6cnW_nPq4y"
      },
      "source": [
        "Анализ Classification Report для метода логистической регресии:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BS-TtgjMKh9"
      },
      "source": [
        "\n",
        "• Precision (точность), Recall (полнота), и F1-score для каждого класса равны 1.00. Это указывает на то, что модель логистической регрессии идеально справилась с классификацией.\n",
        "\n",
        " • Accuracy (точность) также равна 1.00, что означает, что все предсказания модели верны.\n",
        "\n",
        "В целом, вывод свидетельствует о том, что модель логистической регрессии имеет отличную производительность на тестовой выборке, справляясь с классификацией всех трех классов ирисов с высокой точностью и полнотой."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6HZ9lpFLLvR"
      },
      "source": [
        "## Обучение модели с помощью агоритма k-ближайших соседей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nk6m-arcMpeQ"
      },
      "outputs": [],
      "source": [
        "# Создание и обучение модели k-ближайших соседей\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
        "knn_model.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "6FFjO6fSMvLz"
      },
      "outputs": [],
      "source": [
        "# Предсказание на тестовой выборке\n",
        "y_pred_knn = knn_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "47kZZoWbMw_P"
      },
      "outputs": [],
      "source": [
        "# Оценка производительности модели\n",
        "accuracy_knn = accuracy_score(Y_test, y_pred_knn)\n",
        "conf_matrix_knn = confusion_matrix(Y_test, y_pred_knn)\n",
        "classification_report_knn = classification_report(Y_test, y_pred_knn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DARI0Kf4MplN"
      },
      "outputs": [],
      "source": [
        "# Вывод результатов\n",
        "print(\"Accuracy k-ближайших соседей:\", accuracy_knn)\n",
        "print(\"\\nConfusion Matrix k-ближайших соседей:\\n\", conf_matrix_knn)\n",
        "print(\"\\nClassification Report k-ближайших соседей:\\n\", classification_report_knn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkGvdCccOZts"
      },
      "source": [
        "Анализ Confusion matrix для метода k-ближайших соседей:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOKh7GK9OYbQ"
      },
      "source": [
        "• Все элементы на главной диагонали (10, 10, 10) - это True Positives, что\n",
        "означает, что все объекты каждого класса были верно классифицированы.\n",
        "\n",
        " • Нет False Positives (0 вне главной диагонали) и False Negatives (0 вне главной диагонали), что подтверждает отсутствие ошибок классификации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaVonXgNOp6B"
      },
      "source": [
        "Анализ Classification Report для метода k-ближайших соседей:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae7unchYOyga"
      },
      "source": [
        "• Precision, Recall и F1-score для каждого класса равны 1.00. Это указывает на то, что модель k-ближайших соседей идеально справилась с классификацией.\n",
        "\n",
        " • Взвешенное среднее также равно 1.00, что подчеркивает общую точность модели.\n",
        "\n",
        "В целом, результаты для модели k-ближайших соседей также указывают на высокую точность и отсутствие ошибок классификации на данном наборе данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ3qp2zWNIWO"
      },
      "source": [
        "## Обучение модели с помощью Дерева принятия решений"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBFIOboJN43Q"
      },
      "outputs": [],
      "source": [
        "# Создание и обучение модели дерева решений\n",
        "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree_model.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "z9t6hC3iN7Mv"
      },
      "outputs": [],
      "source": [
        "# Предсказание на тестовой выборке\n",
        "y_pred_dt = decision_tree_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Ij-Ss8c8N91s"
      },
      "outputs": [],
      "source": [
        "# Оценка производительности модели\n",
        "accuracy_dt = accuracy_score(Y_test, y_pred_dt)\n",
        "conf_matrix_dt = confusion_matrix(Y_test, y_pred_dt)\n",
        "classification_report_dt = classification_report(Y_test, y_pred_dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJWLzLpfN3vx"
      },
      "outputs": [],
      "source": [
        "# Вывод результатов\n",
        "print(\"Accuracy дерева решений:\", accuracy_dt)\n",
        "print(\"\\nConfusion Matrix дерева решений:\\n\", conf_matrix_dt)\n",
        "print(\"\\nClassification Report дерева решений:\\n\", classification_report_dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQq_DmgGO4Aw"
      },
      "source": [
        "Анализ Confusion Matrix для дерева решений:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5N3kdGxO-HW"
      },
      "source": [
        "• Все элементы на главной диагонали (10, 10, 10) - это True Positives, что означает, что все объекты каждого класса были верно классифицированы.\n",
        "\n",
        " • Нет False Positives (0 вне главной диагонали) и False Negatives (0 вне главной диагонали), что подтверждает отсутствие ошибок классификации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN1YO2ziO-QM"
      },
      "source": [
        "Анализ Classification Report для дерева решений:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_cSgGKdO-Z3"
      },
      "source": [
        "• Precision, Recall и F1-score для каждого класса равны 1.00. Это указывает на то, что модель дерева решений идеально справилась с классификацией.\n",
        "\n",
        " • Взвешенное среднее также равно 1.00, что подчеркивает общую точность модели.\n",
        "\n",
        "Результаты для модели дерева решений также свидетельствуют о высокой точности и отсутствии ошибок классификации на данном наборе данных. В целом, все три модели показывают идеальные результаты на предоставленных данных Iris."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtMrFvWzQGda"
      },
      "source": [
        "### Метрики MAE (Mean Absolute Error) и MSE (Mean Squared Error) обычно используются в задачах регрессии, а не в задачах классификации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7Knnjt9Q13z"
      },
      "source": [
        "# Выбор наилучшей модели на основе вычисленных метрик\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr98Sb2YQ5UX"
      },
      "source": [
        "В ходе анализа и обучения трех различных моделей машинного обучения – логистической регрессии, k-ближайших соседей и дерева решений, на наборе данных ирисов – были получены высокие показатели производительности. Все три модели достигли максимальной точности (Accuracy) в 1.0, что свидетельствует о безошибочной классификации на тестовой выборке.\n",
        "\n",
        "Подробный анализ метрик, таких как Precision, Recall и F1-score для каждого класса, а также матрицы ошибок (Confusion Matrix), подтвердил отсутствие ложных срабатываний и упущений для всех классов. Это говорит о высокой надежности всех трех моделей в различении классов ирисов (Iris-setosa, Iris-versicolor, Iris-virginica).\n",
        "\n",
        "Таким образом, на основании анализа метрик и общей точности, все три модели оказались идеальными для данной задачи классификации. Однако, учитывая простоту и интерпретируемость, логистическая регрессия может быть предпочтительной в реальных условиях, если обеспечивает достаточную производительность. В конечном итоге, выбор модели может зависеть от специфики бизнес-задачи, требований к интерпретируемости и ресурсных ограничений."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
